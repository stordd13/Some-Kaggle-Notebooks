{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd \nfrom matplotlib import pyplot as plt\nfrom path import Path\nimport gc\n\nimport optuna\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom scipy.special import erfinv\n\nimport tensorflow as tf\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu,True)\n    \nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l1\nfrom tensorflow.keras.metrics import AUC\n\nfrom tensorflow.keras.utils import get_custom_objects\nfrom tensorflow.keras.layers import Activation, LeakyReLU\nget_custom_objects().update({'leaky-relu':Activation(LeakyReLU(alpha=0.2))})\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T18:20:16.617659Z","iopub.execute_input":"2023-06-21T18:20:16.618176Z","iopub.status.idle":"2023-06-21T18:20:27.068045Z","shell.execute_reply.started":"2023-06-21T18:20:16.618141Z","shell.execute_reply":"2023-06-21T18:20:27.066924Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/porto-seguro-safe-driver-prediction/sample_submission.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/train.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"def gpu_cleanup(objects):\n    if objects:\n        del(objects)\n        K.clear_session()\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:20:37.053515Z","iopub.execute_input":"2023-06-21T18:20:37.054364Z","iopub.status.idle":"2023-06-21T18:20:37.059942Z","shell.execute_reply.started":"2023-06-21T18:20:37.054329Z","shell.execute_reply":"2023-06-21T18:20:37.058810Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Config:\n    input_path = Path('/kaggle/input/porto-seguro-safe-driver-prediction')\n    dae_batch_size = 128 \n    dae_num_epoch = 50\n    dae_architecture = [1500,1500,1500]\n    reuse_autoencoder = False\n    \n    batch_size = 128\n    num_epoch = 150\n\n    units = [64,32]\n    input_dropout = 0.06\n    dropout = 0.08\n    activation = 'selu'\n    \n    cv_folds = 5\n    nas = False\n    random_state = 0 \n\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:20:37.284880Z","iopub.execute_input":"2023-06-21T18:20:37.285665Z","iopub.status.idle":"2023-06-21T18:20:37.292553Z","shell.execute_reply.started":"2023-06-21T18:20:37.285633Z","shell.execute_reply":"2023-06-21T18:20:37.291410Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(config.input_path / 'train.csv', index_col='id')\ntest = pd.read_csv(config.input_path / 'test.csv', index_col='id')\nsubmission = pd.read_csv(config.input_path / 'sample_submission.csv', index_col='id')\n\ncalc_features = [feat for feat in train.columns if '_calc' in feat]\ncat_features = [feat for feat in train.columns if '_cat' in feat]\n\ntarget = train[\"target\"]\ntrain = train.drop(['target'],axis=1)\n\ntrain = train.drop(calc_features, axis=1)\ntest = test.drop(calc_features, axis=1)\n\ntrain = pd.get_dummies(train, columns = cat_features)\ntest = pd.get_dummies(test, columns = cat_features)\n\nassert((train.columns==test.columns).all())","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:20:44.323102Z","iopub.execute_input":"2023-06-21T18:20:44.323481Z","iopub.status.idle":"2023-06-21T18:21:02.448107Z","shell.execute_reply.started":"2023-06-21T18:20:44.323451Z","shell.execute_reply":"2023-06-21T18:21:02.447019Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(\"Applying GaussRank to columns: \", end='')\nto_normalize = list()\nfor k, col in enumerate(train.columns):\n    if '_bin' not in col and '_cat' not in col and '_missing' not in col:\n        to_normalize.append(col)\nprint(to_normalize)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:21:02.450190Z","iopub.execute_input":"2023-06-21T18:21:02.450740Z","iopub.status.idle":"2023-06-21T18:21:02.459486Z","shell.execute_reply.started":"2023-06-21T18:21:02.450686Z","shell.execute_reply":"2023-06-21T18:21:02.458279Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Applying GaussRank to columns: ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15']\n","output_type":"stream"}]},{"cell_type":"code","source":"def to_gauss(x): return np.sqrt(2)* erfinv(x)\n\ndef normalize(data, norm_cols):\n    n = data.shape[0]\n    for col in norm_cols:\n        sorted_idx = data[col].sort_values().index.tolist()\n        uniform = np.linspace(start=-0.99, stop=0.99, num=n)\n        normal = to_gauss(uniform)\n        normalized_col = pd.Series(index = sorted_idx, data=normal)\n        data[col] = normalized_col\n    return data\n\ntrain = normalize(train, to_normalize)\ntest = normalize(test, to_normalize)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:21:02.461537Z","iopub.execute_input":"2023-06-21T18:21:02.462381Z","iopub.status.idle":"2023-06-21T18:21:15.725076Z","shell.execute_reply.started":"2023-06-21T18:21:02.462322Z","shell.execute_reply":"2023-06-21T18:21:15.723912Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"features = train.columns\ntrain_index = train.index\ntest_index = test.index\n\ntrain = train.values.astype(np.float32)\ntest = test.values.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:21:15.727678Z","iopub.execute_input":"2023-06-21T18:21:15.728113Z","iopub.status.idle":"2023-06-21T18:21:17.148328Z","shell.execute_reply.started":"2023-06-21T18:21:15.728075Z","shell.execute_reply":"2023-06-21T18:21:17.147210Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def plt_keras_history(history, measures):\n    row = len(measures) // 2 + len(measures)%2\n    fig, panels = plt.subplots(rows, 2, figsize=(15,5))\n    plt.subplots_adjust(top = 0.99, bottom = 0.01,\n                       hspace = 0.4, wspace = 0.2)\n    try:\n        panels = [item for sublist in panels for item in sublist]\n    except:\n        pass\n    for k, measure in enumerate(measures):\n        panel = panels[k]\n        panel.set_title(measure + 'history')\n        panel.plot(history.epoch, history.history[measure],\n                  label='Train ' + measure)\n        try:\n            panel.plot(history.epoch, history.history['val_'+measure],\n                      label = \"Validation \"+measure)\n        except:\n            pass\n        panel.set(xlabel='epochs', ylabel=measure)\n        panel.legend()\n    plt.show(fig)\n    \n\nfrom numba import jit\n@jit\n\ndef eval_gini(y_true, y_pred):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_pred)]\n    ntrue = 0\n    gini = 0\n    delta = 0 \n    n = len(y_true)\n    for i in range(n-1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i \n        gini += y_i * delta\n        delta += 1 - y_i\n    gini = 1 - 2 * gini / (ntrue *(n - ntrue))\n    return gini ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:21:17.149669Z","iopub.execute_input":"2023-06-21T18:21:17.150049Z","iopub.status.idle":"2023-06-21T18:21:17.821613Z","shell.execute_reply.started":"2023-06-21T18:21:17.150016Z","shell.execute_reply":"2023-06-21T18:21:17.820600Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/2679286598.py:28: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n  def eval_gini(y_true, y_pred):\n","output_type":"stream"}]},{"cell_type":"code","source":"## create a generator that provides shuffled chunks of the data based on batch size.\n\ndef batch_generator(x, batch_size, shuffle=True, random_state = None):\n    batch_index = 0 \n    n = x.shape[0]\n    while True:\n        if batch_index == 0:\n            index_array = np.arange(n)\n            if shuffle:\n                np.random.seed(seed=random_state)\n                index_array = np.random_permutation(n)\n        current_index = (batch_index * batch_size)%n\n        if n >= current_index + batch_size:\n            current_batch_size = batch_size\n            batch_index +=1\n        else:\n            current_batch_size = n - current_index\n            batch_index=0\n        batch = x[index_array[current_index: current_index + current_batch_size]]\n        \n        yield batch","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:06:06.997877Z","iopub.execute_input":"2023-06-20T17:06:06.998269Z","iopub.status.idle":"2023-06-20T17:06:07.004971Z","shell.execute_reply.started":"2023-06-20T17:06:06.998238Z","shell.execute_reply":"2023-06-20T17:06:07.003737Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"## mixup generator that return batches of data whose values have been partially swapped\n## to create some noise and augment the data to avoid the DAE overfitting to the training dataset.\n## Can be viewed as a way to inject random values into the dataset and create many more examples\n## to be used for trianing. 15% of random values at each batch\n## Also, since the random values are picked from the same features it's not totally random\n## because they are from the same distribution of the original features\n\ndef mixup_generator(X, batch_size, swaprate =0.15, shuffle = True, random_state = None):\n    if random_state is None:\n        random_state = np.randint(0,999)\n    num_features = X.shape[1]\n    num_swaps = int(num_features * swaprate)\n    generator_a = batch_generator(X, batch_size, shuffle, random_state)\n    generator_b = batch_generator(X, batch_size, shuffle, random_state+1)\n    \n    while True:\n        batch = next(generator_a)\n        mixed_batch = batch.copy()\n        effective_batch_size = batch.shape[0]\n        alternative_batch = next(generator_b)\n        assert((batch != alternative_batch).any())\n        for i in range(effective_batch_size):\n            swap_idx = np.random.choice(num_features, num_swaps, replace=False)\n            mixed_batch[i, swap_idx] = alternative_batch[i,swap_idx]\n        yield (mixed_batch, batch)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:36:25.527981Z","iopub.execute_input":"2023-06-21T18:36:25.528377Z","iopub.status.idle":"2023-06-21T18:36:25.539822Z","shell.execute_reply.started":"2023-06-21T18:36:25.528345Z","shell.execute_reply":"2023-06-21T18:36:25.538791Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"### the get DAE is the function that buils the denoising autoencoder.\n\ndef get_DAE(X, architecture = [1500,1500,1500]):\n    features = X.shape[1]\n    inputs = Input((features,))\n    for i, nodes in enumerature(architecture):\n        layer = Dense(nodes, activation='relu', \n                     use_bias=False, name = f\"code_{i+1}\")\n        if i==O:\n            x = layer(inputs)\n        else:\n            x = layer(x)\n        x = BatchNormalization()(x)\n    outputs = Dense(features, activation = 'linear')(x)\n    model = Model(inputs=inputs, outputs = outputs)\n    model.compile(optimizer='adam', loss='mse',\n                 metrics=['mse', 'mae'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:41:57.124560Z","iopub.execute_input":"2023-06-21T18:41:57.124960Z","iopub.status.idle":"2023-06-21T18:41:57.133651Z","shell.execute_reply.started":"2023-06-21T18:41:57.124930Z","shell.execute_reply":"2023-06-21T18:41:57.132426Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def extract_dae_features(autoencoder, X, layers=[3], batch_size=128):\n    data=[]\n    for layers in layers:\n        if layer==0:\n            data.append(X)\n        else:\n            get_layer_output = Model([autoencoder.layers[0].input],\n                                    [autoencoer.layers[layer].output])\n            layer_output = get_layer_output.predict(X, batch_size=batch_size)\n            data.append(layer_output)\n            \n    data = np.hstack(data)\n    return data\n            ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:45:25.741618Z","iopub.execute_input":"2023-06-21T18:45:25.742307Z","iopub.status.idle":"2023-06-21T18:45:25.749663Z","shell.execute_reply.started":"2023-06-21T18:45:25.742271Z","shell.execute_reply":"2023-06-21T18:45:25.748414Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def autoencoder_fitting(X_train, X_valid, filename = 'dae', random_state = None,\n                       suppress_output=False):\n    if suppress_output:\n        verbose=0\n    else:\n        verbose=2\n        print(\"Fitting a denoising autoencoder\")\n        tf.random.set_seed(seed=random_state)\n        generator = mixup_generator(X_train,\n                                   batch_size=config.dae_batch_size,\n                                   swaprate=0.15,\n                                   random_state=config.random_state)\n        dae = get_DAE(X_train, architecture=config.dae_architecture)\n        steps_per_epoch = np.ceil(X_train.shape[0]/config.dae_batch_size)\n        \n        early_stopping = EarlyStopping(monitor='val_mse',\n                                      mode='min',\n                                      patience=5,\n                                      restore_best_weights=True,\n                                      verbose=0)\n        history = dae.fit(generator,\n                         steps_per_epoch = steps_per_epoch,\n                         epochs = config.dae_num_epoch,\n                         validation_data=(X_valid, X_valid),\n                         callbakcs = [early_stopping],\n                         verbose = verbose)\n        if not suppress_output: plot_keras_history(history,measures=['mse','mae'])\n        dae.save(filename)\n        return dae","metadata":{"execution":{"iopub.status.busy":"2023-06-21T18:53:11.263942Z","iopub.execute_input":"2023-06-21T18:53:11.264413Z","iopub.status.idle":"2023-06-21T18:53:11.282337Z","shell.execute_reply.started":"2023-06-21T18:53:11.264375Z","shell.execute_reply":"2023-06-21T18:53:11.281190Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}