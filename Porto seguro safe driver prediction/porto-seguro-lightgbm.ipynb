{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \nimport optuna\nimport lightgbm as lgb\nfrom path import Path\nfrom sklearn.model_selection import StratifiedKFold\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-19T16:27:40.104075Z","iopub.execute_input":"2023-06-19T16:27:40.104439Z","iopub.status.idle":"2023-06-19T16:27:43.647311Z","shell.execute_reply.started":"2023-06-19T16:27:40.104408Z","shell.execute_reply":"2023-06-19T16:27:43.646398Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/porto-seguro-safe-driver-prediction/sample_submission.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/train.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"class Config:\n    input_path = Path('../input/porto-seguro-safe-driver-prediction')\n    optuna_lgb = False\n    n_estimators = 1500 \n    early_stopping_round = 150\n    cv_folds = 5\n    random_state = 0\n    params = {'objective':'binary',\n             'boosting_type':'gbdt',\n             'learning_rate': 0.01,\n             'max_bins':25,\n             'num_leaves':31,\n             'min_child_samples':1500,\n             'colsample_bytree':0.7,\n             'subsample_freq':1,\n             'subsample':0.7,\n             'reg_alpha':1.0,\n             'reg_lambda':1.0,\n             'verbosity':0,\n             'random_state':0}\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:27:43.651391Z","iopub.execute_input":"2023-06-19T16:27:43.652514Z","iopub.status.idle":"2023-06-19T16:27:43.661159Z","shell.execute_reply.started":"2023-06-19T16:27:43.652481Z","shell.execute_reply":"2023-06-19T16:27:43.659331Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(config.input_path/'train.csv', index_col='id')\ntest = pd.read_csv(config.input_path/'test.csv', index_col='id')\nsubmission = pd.read_csv(config.input_path/'sample_submission.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:27:43.663678Z","iopub.execute_input":"2023-06-19T16:27:43.664197Z","iopub.status.idle":"2023-06-19T16:27:51.346588Z","shell.execute_reply.started":"2023-06-19T16:27:43.664168Z","shell.execute_reply":"2023-06-19T16:27:51.345065Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"calc_features = [feat for feat in train.columns if '_calc' in feat]\ncat_features = [feat for feat in train.columns if '_cat' in feat]\n\ntarget = train['target']\ntrain = train.drop('target', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:27:51.348845Z","iopub.execute_input":"2023-06-19T16:27:51.349200Z","iopub.status.idle":"2023-06-19T16:27:51.413297Z","shell.execute_reply.started":"2023-06-19T16:27:51.349169Z","shell.execute_reply":"2023-06-19T16:27:51.410814Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"### It was argued in the discussion that the calc features can be dropped. Since the are \n### engineered features, they do not contains new information in respect of their original\n### features, but they just add noise to any model trained that comprises them\n\ntrain = train.drop(calc_features, axis=1)\ntest = test.drop(calc_features, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:27:51.415087Z","iopub.execute_input":"2023-06-19T16:27:51.415383Z","iopub.status.idle":"2023-06-19T16:27:51.542189Z","shell.execute_reply.started":"2023-06-19T16:27:51.415356Z","shell.execute_reply":"2023-06-19T16:27:51.540180Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install BorutaShap","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:40:53.527329Z","iopub.execute_input":"2023-06-19T16:40:53.527682Z","iopub.status.idle":"2023-06-19T16:41:04.731077Z","shell.execute_reply.started":"2023-06-19T16:40:53.527655Z","shell.execute_reply":"2023-06-19T16:41:04.729216Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting BorutaShap\n  Downloading BorutaShap-1.0.16-py3-none-any.whl (13 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (1.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (4.64.1)\nRequirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (0.13.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (3.6.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (1.5.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (1.23.5)\nRequirement already satisfied: shap>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (0.41.0)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (0.12.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (1.10.1)\nRequirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (21.3)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (0.0.7)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (0.57.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (2.2.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (9.5.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->BorutaShap) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->BorutaShap) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->BorutaShap) (3.1.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels->BorutaShap) (0.5.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels->BorutaShap) (1.16.0)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap>=0.34.0->BorutaShap) (0.40.0)\nInstalling collected packages: BorutaShap\nSuccessfully installed BorutaShap-1.0.16\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# **FEATURES SELECTION**\n### Using Boruta-SHAP","metadata":{}},{"cell_type":"code","source":"## look Boruta features elimination notebook ##\n\n# Importing core libraries\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport pprint\nimport joblib\nfrom functools import partial\n\n# Suppressing warnings because of skopt verbosity\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Classifier/Regressor\nfrom xgboost import XGBRegressor\n\n# Feature selection\n#from BorutaShap import BorutaShap\n\n# Data processing\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA, FactorAnalysis\nfrom sklearn.mixture import GaussianMixture\n\n# Validation\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:41:38.509901Z","iopub.execute_input":"2023-06-19T16:41:38.510291Z","iopub.status.idle":"2023-06-19T16:41:38.660510Z","shell.execute_reply.started":"2023-06-19T16:41:38.510261Z","shell.execute_reply":"2023-06-19T16:41:38.658959Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train = pd.get_dummies(train, columns=cat_features)\ntest = pd.get_dummies(test, columns=cat_features)\n\nassert((train.columns == test.columns).all())","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:41:40.319844Z","iopub.execute_input":"2023-06-19T16:41:40.320200Z","iopub.status.idle":"2023-06-19T16:41:42.365365Z","shell.execute_reply.started":"2023-06-19T16:41:40.320174Z","shell.execute_reply":"2023-06-19T16:41:42.364244Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from numba import jit\n\n@jit\ndef eval_gini(y_true,y_pred):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_pred)]\n    ntrue=0\n    gini=0\n    delta=0\n    n = len(y_true)\n    for i in range(n-1,-1,-1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i*delta\n        delta += 1 - y_i\n    gini = 1- 2*gini / (ntrue*(n-ntrue))\n    return gini\n\ndef gini_lgb(y_true, y_pred):\n    eval_name = 'normalized_gini_coef'\n    eval_result = eval_gini(y_true,y_pred)\n    is_higher_better = True\n    return eval_name, eval_result, is_higher_better","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:41:42.367039Z","iopub.execute_input":"2023-06-19T16:41:42.367402Z","iopub.status.idle":"2023-06-19T16:41:43.785256Z","shell.execute_reply.started":"2023-06-19T16:41:42.367373Z","shell.execute_reply":"2023-06-19T16:41:43.784286Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"if config.optuna_lgb:\n    def objective(trial):\n            params = {\n             'learning_rate': trial.suggest_float('learning_rate',0.01,1.0),\n             'num_leaves':trial.suggest_int(\"num_leaves\", 3,255),\n             'min_child_samples':trial.suggest_int(\"min_chil_samples\",3,3000),\n             'colsample_bytree':trial.suggest_float(\"colsample_bytree\",0.1,1.0),\n             'subsample_freq':trial.suggest_int(\"subsample_freq\",0,10),\n             'subsample':trial.suggest_float(\"subsample\",0.1,1.0),\n             'reg_alpha':trial.suggest_loguniform(\"reg_alpha\",1e-9,10.0),\n             'reg_lambda':trial.suggest_loguniform(\"reg_lambda\",1e-9,10.0)\n            }\n            score = list()\n            skf = StratifiedKFold(n_splits=config.cv_folds,shuffle=True,\n                                 random_state=config.random_state)\n            \n            for train_idx, valid_idx in skf.split(train, target):\n                X_train = train.iloc[train_idx]\n                y_train = target.iloc[train_idx]\n                X_valid = train.iloc[valid_idx]\n                y_valid = target.iloc[valid_idx]\n                \n                model = lgb.LGBMClassifier(**params, \n                                           n_estimators=1500,\n                                          early_stopping_round = 150,\n                                          force_row_wise=True)\n                callbacks = [lgb.early_stopping(stopping_rounds=150,\n                                               verbose=False)]\n                model.fit(X_train, y_train,\n                         eval_set=[(X_valid,y_valid)],\n                         eval_metric = gini_lgb,callbacks=callbacks)\n                score.append(model.best_score_['valid_0']['normalized_gini_coef'])\n            return np.mean(score)\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=300)\n    print(\"Best Gini Normalized Score\", study.best_value)\n    print(\"Best parameteres\", study.best_params)\n        \n    params = {'objective':'binary',\n                 'boosting_type':'gbdt',\n                  'verbosity':0,\n                  'random_state':0}\n    params.update(study.best_params)\nelse:\n    params = config.params\n            \n                ","metadata":{"execution":{"iopub.status.busy":"2023-06-19T16:41:43.864312Z","iopub.execute_input":"2023-06-19T16:41:43.866402Z","iopub.status.idle":"2023-06-19T16:41:43.877767Z","shell.execute_reply.started":"2023-06-19T16:41:43.866374Z","shell.execute_reply":"2023-06-19T16:41:43.876564Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"%%time \npreds = np.zeros(len(test))\noof = np.zeros(len(train))\nmetric_evaluations = list()\n\nskf = StratifiedKFold(n_splits = config.cv_folds, shuffle=True, random_state=config.random_state)\n\nfor idx, (train_idx, valid_idx) in enumerate(skf.split(train, target)):\n    print(f\"CV fold {idx}\")\n    X_train, y_train = train.iloc[train_idx], target.iloc[train_idx]\n    X_valid, y_valid = train.iloc[valid_idx], target.iloc[valid_idx]\n    model = lgb.LGBMClassifier(**params, n_estimators=config.n_estimators, \n                               early_stopping_round = config.early_stopping_round, \n                               force_row_wise = True )\n    callbacks = [lgb.early_stopping(stopping_rounds=150),\n                                    lgb.log_evaluation(period=100, show_stdv=False)]\n    model.fit(X_train, y_train,\n                eval_set=[(X_valid,y_valid)],\n                eval_metric = gini_lgb,callbacks=callbacks)\n    metric_evaluations.append(model.best_score_['valid_0']['normalized_gini_coef'])\n    preds += (model.predict_proba(test, num_iteration = model.best_iteration_)[:,1]/skf.n_splits)\n    \n    oof[valid_idx] = model.predict_proba(X_valid,num_iteration=model.best_iteration_)[:,1]\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-19T17:02:44.313304Z","iopub.execute_input":"2023-06-19T17:02:44.313626Z","iopub.status.idle":"2023-06-19T17:12:42.737323Z","shell.execute_reply.started":"2023-06-19T17:02:44.313605Z","shell.execute_reply":"2023-06-19T17:12:42.736141Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"CV fold 0\nTraining until validation scores don't improve for 150 rounds\n[100]\tvalid_0's binary_logloss: 0.153243\tvalid_0's normalized_gini_coef: 0.271457\n[200]\tvalid_0's binary_logloss: 0.15228\tvalid_0's normalized_gini_coef: 0.280599\n[300]\tvalid_0's binary_logloss: 0.15185\tvalid_0's normalized_gini_coef: 0.286829\n[400]\tvalid_0's binary_logloss: 0.151651\tvalid_0's normalized_gini_coef: 0.289906\n[500]\tvalid_0's binary_logloss: 0.151543\tvalid_0's normalized_gini_coef: 0.291906\n[600]\tvalid_0's binary_logloss: 0.151473\tvalid_0's normalized_gini_coef: 0.293377\n[700]\tvalid_0's binary_logloss: 0.151437\tvalid_0's normalized_gini_coef: 0.293827\n[800]\tvalid_0's binary_logloss: 0.151417\tvalid_0's normalized_gini_coef: 0.294276\n[900]\tvalid_0's binary_logloss: 0.15142\tvalid_0's normalized_gini_coef: 0.294119\nEarly stopping, best iteration is:\n[806]\tvalid_0's binary_logloss: 0.151416\tvalid_0's normalized_gini_coef: 0.294311\nCV fold 1\nTraining until validation scores don't improve for 150 rounds\n[100]\tvalid_0's binary_logloss: 0.153553\tvalid_0's normalized_gini_coef: 0.255568\n[200]\tvalid_0's binary_logloss: 0.152779\tvalid_0's normalized_gini_coef: 0.261176\n[300]\tvalid_0's binary_logloss: 0.152509\tvalid_0's normalized_gini_coef: 0.264598\n[400]\tvalid_0's binary_logloss: 0.152392\tvalid_0's normalized_gini_coef: 0.266942\n[500]\tvalid_0's binary_logloss: 0.152334\tvalid_0's normalized_gini_coef: 0.268508\n[600]\tvalid_0's binary_logloss: 0.15231\tvalid_0's normalized_gini_coef: 0.269259\n[700]\tvalid_0's binary_logloss: 0.152308\tvalid_0's normalized_gini_coef: 0.269299\n[800]\tvalid_0's binary_logloss: 0.1523\tvalid_0's normalized_gini_coef: 0.269814\n[900]\tvalid_0's binary_logloss: 0.152298\tvalid_0's normalized_gini_coef: 0.270119\nCV fold 2\nTraining until validation scores don't improve for 150 rounds\n[100]\tvalid_0's binary_logloss: 0.15349\tvalid_0's normalized_gini_coef: 0.250438\n[200]\tvalid_0's binary_logloss: 0.152638\tvalid_0's normalized_gini_coef: 0.261463\n[300]\tvalid_0's binary_logloss: 0.152286\tvalid_0's normalized_gini_coef: 0.267762\n[400]\tvalid_0's binary_logloss: 0.15211\tvalid_0's normalized_gini_coef: 0.271644\n[500]\tvalid_0's binary_logloss: 0.152015\tvalid_0's normalized_gini_coef: 0.274152\n[600]\tvalid_0's binary_logloss: 0.151963\tvalid_0's normalized_gini_coef: 0.275609\n[700]\tvalid_0's binary_logloss: 0.151933\tvalid_0's normalized_gini_coef: 0.276576\n[800]\tvalid_0's binary_logloss: 0.151919\tvalid_0's normalized_gini_coef: 0.276946\n[900]\tvalid_0's binary_logloss: 0.151906\tvalid_0's normalized_gini_coef: 0.277448\n[1000]\tvalid_0's binary_logloss: 0.151911\tvalid_0's normalized_gini_coef: 0.277363\nEarly stopping, best iteration is:\n[924]\tvalid_0's binary_logloss: 0.151902\tvalid_0's normalized_gini_coef: 0.277638\nCV fold 3\nTraining until validation scores don't improve for 150 rounds\n[100]\tvalid_0's binary_logloss: 0.153151\tvalid_0's normalized_gini_coef: 0.28492\n[200]\tvalid_0's binary_logloss: 0.152081\tvalid_0's normalized_gini_coef: 0.294826\n[300]\tvalid_0's binary_logloss: 0.151594\tvalid_0's normalized_gini_coef: 0.301155\n[400]\tvalid_0's binary_logloss: 0.151332\tvalid_0's normalized_gini_coef: 0.305416\n[500]\tvalid_0's binary_logloss: 0.151173\tvalid_0's normalized_gini_coef: 0.308713\n[600]\tvalid_0's binary_logloss: 0.151074\tvalid_0's normalized_gini_coef: 0.310518\n[700]\tvalid_0's binary_logloss: 0.151014\tvalid_0's normalized_gini_coef: 0.311803\n[800]\tvalid_0's binary_logloss: 0.150976\tvalid_0's normalized_gini_coef: 0.312533\n[900]\tvalid_0's binary_logloss: 0.150947\tvalid_0's normalized_gini_coef: 0.31291\n[1000]\tvalid_0's binary_logloss: 0.150928\tvalid_0's normalized_gini_coef: 0.313239\n[1100]\tvalid_0's binary_logloss: 0.15092\tvalid_0's normalized_gini_coef: 0.313284\n[1200]\tvalid_0's binary_logloss: 0.150921\tvalid_0's normalized_gini_coef: 0.313124\nCV fold 4\nTraining until validation scores don't improve for 150 rounds\n[100]\tvalid_0's binary_logloss: 0.153417\tvalid_0's normalized_gini_coef: 0.259211\n[200]\tvalid_0's binary_logloss: 0.152528\tvalid_0's normalized_gini_coef: 0.268649\n[300]\tvalid_0's binary_logloss: 0.152123\tvalid_0's normalized_gini_coef: 0.27534\n[400]\tvalid_0's binary_logloss: 0.15192\tvalid_0's normalized_gini_coef: 0.279392\n[500]\tvalid_0's binary_logloss: 0.151813\tvalid_0's normalized_gini_coef: 0.28184\n[600]\tvalid_0's binary_logloss: 0.151733\tvalid_0's normalized_gini_coef: 0.283741\n[700]\tvalid_0's binary_logloss: 0.151682\tvalid_0's normalized_gini_coef: 0.284936\n[800]\tvalid_0's binary_logloss: 0.151647\tvalid_0's normalized_gini_coef: 0.286006\n[900]\tvalid_0's binary_logloss: 0.151625\tvalid_0's normalized_gini_coef: 0.28652\n[1000]\tvalid_0's binary_logloss: 0.151608\tvalid_0's normalized_gini_coef: 0.286903\n[1100]\tvalid_0's binary_logloss: 0.151595\tvalid_0's normalized_gini_coef: 0.287265\n[1200]\tvalid_0's binary_logloss: 0.15159\tvalid_0's normalized_gini_coef: 0.287404\n[1300]\tvalid_0's binary_logloss: 0.151592\tvalid_0's normalized_gini_coef: 0.287313\n[1400]\tvalid_0's binary_logloss: 0.151593\tvalid_0's normalized_gini_coef: 0.287344\nCPU times: user 28min 31s, sys: 44.2 s, total: 29min 15s\nWall time: 9min 58s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"LightGBM CV normalized gin coefficient: {np.mean(metric_evaluations):0.3f}\"\n      f\"({np.std(metric_evaluations):0.3f})\")","metadata":{"execution":{"iopub.status.busy":"2023-06-19T17:32:50.804828Z","iopub.execute_input":"2023-06-19T17:32:50.805170Z","iopub.status.idle":"2023-06-19T17:32:50.811396Z","shell.execute_reply.started":"2023-06-19T17:32:50.805143Z","shell.execute_reply":"2023-06-19T17:32:50.809787Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"LightGBM CV normalized gin coefficient: 0.289(0.015)\n","output_type":"stream"}]},{"cell_type":"code","source":"submission['target']=preds\nsubmission.to_csv('lgb_submission.csv')\n\noofs = pd.DataFrame({'id':train.index,'target':oof})\noofs.to_csv('lgb_oof.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-19T17:32:57.834602Z","iopub.execute_input":"2023-06-19T17:32:57.834962Z","iopub.status.idle":"2023-06-19T17:33:00.512203Z","shell.execute_reply.started":"2023-06-19T17:32:57.834935Z","shell.execute_reply":"2023-06-19T17:33:00.510843Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}